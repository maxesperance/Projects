{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_using_TF2_and_BERT.ipynb","provenance":[{"file_id":"1hMLd5-r82FrnFnBub-B-fVW78Px4KPX1","timestamp":1587333874208}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2IjSWx7-O8yY"},"source":["# Natural Language Processing using BERT\n","\n","Please study AMA Lecture 12 \"Natural Language Processing Using BERT\" before practicing this code."]},{"cell_type":"code","metadata":{"id":"m76ms0rrtQ8d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619066029485,"user_tz":300,"elapsed":20045,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"9868be97-66df-4866-8d8a-cd8cd146faab"},"source":["# mount your Google Drive so you can locate your data files.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aYS2t29Im7o1","executionInfo":{"status":"ok","timestamp":1619066031077,"user_tz":300,"elapsed":290,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["import numpy as np\n","import pandas as pd"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"1HzU3Wionpo9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619066034332,"user_tz":300,"elapsed":1845,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"507b316b-592d-4c1b-e81b-f0ae03280f84"},"source":["# Need tf version >=2.0 and hub version >=0.7\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","print(\"TF version: \", tf.__version__)\n","print(\"Hub version: \", hub.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TF version:  2.4.1\n","Hub version:  0.12.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SOunH6Q4nsEf","executionInfo":{"status":"ok","timestamp":1619066037453,"user_tz":300,"elapsed":278,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cyn23fDFJpZ8"},"source":["## Case study: the IMDB dataset\n","\n","This is a widely used large dataset for text mining from a [2011 ACL meeting paper](https://ai.stanford.edu/~amaas/data/sentiment/) by Maas et al. I processed the data so it fits in a single CSV file 'IMDB_small.csv'.\n","\n","The original dataset has 50000 balanced records, and the data file takes too long to upload to Google Colab. File 'IMDB_small.csv' contains a smaller 10000-record balanced sample, where the first 5000 are negative reviews and the rest are positive reviews."]},{"cell_type":"code","metadata":{"id":"jsAPeTuHphgT","colab":{"base_uri":"https://localhost:8080/","height":198},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1619066096907,"user_tz":300,"elapsed":373,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"8f6ceb85-7ce4-4641-f6d9-c46c8030fe07"},"source":["# load the IMDB dataset\n","df = pd.read_csv('/content/drive/MyDrive/AMA/12_NLP_using_BERT/IMDB_small.csv')\n","df.head()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Congratulations to Christina Ricci for making ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Another British cinema flag waver. Real garbag...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hi there. I watched the first part when it cam...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>If you merely look at the cover of this movie,...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>This movie was extremely depressing.   The cha...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review  sentiment\n","0  Congratulations to Christina Ricci for making ...          0\n","1  Another British cinema flag waver. Real garbag...          0\n","2  Hi there. I watched the first part when it cam...          0\n","3  If you merely look at the cover of this movie,...          0\n","4  This movie was extremely depressing.   The cha...          0"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VBNefBTeHcqH","executionInfo":{"status":"ok","timestamp":1619066102801,"user_tz":300,"elapsed":241,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"5e8a8bdc-0365-413a-9781-f0ea4e5e6347"},"source":["df.sentiment.value_counts()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    5000\n","0    5000\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"K_NJpLIpSGTO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619066115854,"user_tz":300,"elapsed":296,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"d9eb3f47-465b-4637-a6b0-0125374f3149"},"source":["# one negative example:\n","import textwrap\n","print(textwrap.fill(df.review[2], 80))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Hi there. I watched the first part when it came out, and I don't remember having\n","left such a bad impression on me as this one.  First, the animation is choppy,\n","wooden, not worked on, lacks naturality - I understand the drawing style was to\n","be of some 'atlantean' kind, but, it could be done with the usual Disney\n","finesse... see \"Tarzan\" to see what I mean. If I didn't see the DISNEY logo in\n","the beginning, I would never say it was a Disney movie.  Second, the plot was\n","more like a PC game style, like a good old quest. Not that it was bad, but it\n","lacked a story that binds the viewer to the characters and their goals. It was\n","inconvincing, at least. The film was meant for children, but this was waaay to\n","childish at times.  Third, the music... I would say it was improper, but it just\n","fits the whole scene with the plot and animation...  Overall, I think this was\n","some kind of an amusement, just by-the-way kind of project by several apprentice\n","animators, just to fill in the count for Disney movies. Sorry to hear that from\n","myself, a big Disney lover...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GfXyJ2aFW0I9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619066129467,"user_tz":300,"elapsed":476,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"c0936a8b-4a46-481e-e649-6c86f2e4a1c2"},"source":["# one positive example:\n","print(textwrap.fill(df.review[5000], 80))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["After losing the Emmy for her performance as Mama Rose in the television version\n","of GYPSY, Bette won an Emmy the following year for BETTE MIDLER: DIVA LAS VEGAS,\n","a live concert special filmed for HBO from Las Vegas. Midler, who has been\n","performing live on stage since the 1970's, proves that she is still one of the\n","most electrifying live performers in the business. From her opening number, her\n","classic \"Friends\", where she descends from the wings atop a beautiful prop\n","cloud, Bette commands the stage with style and charisma from a rap-styled number\n","called \"I Look Good\" she then proves that she has a way with a joke like few\n","other performers in this business as she segues her way through a variety of\n","musical selections. The section of the show where she salutes burlesque goes on\n","a little too long but she does manage to incorporate her old Sophie Tucker jokes\n","here to good advantage (even though she actually forgets one joke in the middle\n","of telling it, but her ad-libbing until she remembers it is hysterical). Bette\n","also treats us to \"Rose's Turn\" from GYPSY and the title tune from her smash\n","film THE ROSE as well as a shameless plug for her hit movie THE FIRST WIVES\n","CLUB. She brings the house down near the end with \"Stay with Me, Baby\" from THE\n","ROSE and her only #1 hit record, \"Wind Beneath My Wings\" from BEACHES. It's a\n","dazzling evening of musical comedy entertainment and for Midler fans, it's a\n","must.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ICTlwBaqsgZO","executionInfo":{"status":"ok","timestamp":1619066141286,"user_tz":300,"elapsed":245,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["# The following codes make it easier for you to adopt\n","# this file for other text mining datasets.\n","DATA_COLUMN = 'review'\n","LABEL_COLUMN = 'sentiment'\n","label_list = [0, 1] #0-negative, 1-positive"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J5HURQ9CIdHs"},"source":["## Introducing BERT\n","\n","**BERT (Bidirectional Encoder Representations from Transformers)** is the state-of-the-art feature extraction model for natural language.\n","\n","Some resources on BERT:\n","- See BERT on paper: https://arxiv.org/pdf/1810.04805.pdf\n","- See BERT on GitHub: https://github.com/google-research/bert\n","- See BERT on TensorHub: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\n","- See 'old' use of BERT for comparison: https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb"]},{"cell_type":"markdown","metadata":{"id":"1dU6PU4emdgQ"},"source":["Next, we will use BERT in four steps:\n","* Import and build the BERT model\n","* Tokenization\n","* Convert tokens to BERT input format\n","* Sentence/word embedding"]},{"cell_type":"markdown","metadata":{"id":"PtaEqbjwrI4s"},"source":["## Importing and building the BERT model\n","\n","This part of code might confuse you a bit for now. We will come back and explain it more."]},{"cell_type":"code","metadata":{"id":"cEbWuAdFqB2S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619066165975,"user_tz":300,"elapsed":6527,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"9ca68c7e-401a-499c-b4a8-07e637bbd842"},"source":["# !pip install sentencepiece\n","!pip install bert-for-tf2\n","import bert"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Collecting bert-for-tf2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/a1/acb891630749c56901e770a34d6bac8a509a367dd74a05daf7306952e910/bert-for-tf2-0.14.9.tar.gz (41kB)\n","\r\u001b[K     |████████                        | 10kB 21.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n","\u001b[?25hCollecting py-params>=0.9.6\n","  Downloading https://files.pythonhosted.org/packages/aa/e0/4f663d8abf83c8084b75b995bd2ab3a9512ebc5b97206fde38cef906ab07/py-params-0.10.2.tar.gz\n","Collecting params-flow>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n","Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n","  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-cp37-none-any.whl size=30535 sha256=06f71b3838f54cea6e0f95cda41ed1950e2a27022c69a536de89ad8cbd8eceaa\n","  Stored in directory: /root/.cache/pip/wheels/a1/04/ee/347bd9f5b821b637c76411d280271a857aece00358896a230f\n","  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-params: filename=py_params-0.10.2-cp37-none-any.whl size=7912 sha256=42d1ff9d5b85dfd3f40bac3ea11f028bf4263f72bf5e159403d3b1675bce1f90\n","  Stored in directory: /root/.cache/pip/wheels/d0/4a/70/ff12450229ff1955abf01f365051d4faae1c20aef53ab4cf09\n","  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for params-flow: filename=params_flow-0.8.2-cp37-none-any.whl size=19472 sha256=68be12dad639949190e978af9894e831f19e6972e8689f738d4b76fe7da19786\n","  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n","Successfully built bert-for-tf2 py-params params-flow\n","Installing collected packages: py-params, params-flow, bert-for-tf2\n","Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IUInJmh7qpvo","executionInfo":{"status":"ok","timestamp":1619066176513,"user_tz":300,"elapsed":240,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["# BERT requires a MAX_SEQ_LENGTH that can be any integer<=512.\n","# Here we pick a smaller number to cut down computation cost.\n","max_seq_length = 256"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"6IqEqHw8pxPo","executionInfo":{"status":"ok","timestamp":1619066437758,"user_tz":300,"elapsed":290,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["# BERT requires the following three types of inputs (more on them later)\n","input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n","                                       name=\"input_word_ids\")\n","input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n","                                   name=\"input_mask\")\n","segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n","                                    name=\"segment_ids\")"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rs-kXm1P39Lo","executionInfo":{"status":"ok","timestamp":1619066457259,"user_tz":300,"elapsed":18177,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["# Now we load the already pre-trained BERT layers\n","bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n","                            trainable=True)\n","pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"LETaImqhruXz","executionInfo":{"status":"ok","timestamp":1619066458680,"user_tz":300,"elapsed":233,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["model = models.Model(inputs=[input_word_ids, input_mask, segment_ids], \n","                     outputs=[pooled_output, sequence_output])"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"cAxh7sZe3EcV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619066462345,"user_tz":300,"elapsed":254,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"7a447ce8-cfb3-42f5-e34b-a31c544c0088"},"source":["model.summary()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_word_ids (InputLayer)     [(None, 256)]        0                                            \n","__________________________________________________________________________________________________\n","input_mask (InputLayer)         [(None, 256)]        0                                            \n","__________________________________________________________________________________________________\n","segment_ids (InputLayer)        [(None, 256)]        0                                            \n","__________________________________________________________________________________________________\n","keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n","                                                                 input_mask[0][0]                 \n","                                                                 segment_ids[0][0]                \n","==================================================================================================\n","Total params: 109,482,241\n","Trainable params: 109,482,240\n","Non-trainable params: 1\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FShEbcDZmvF_"},"source":["## BERT for tokenization"]},{"cell_type":"markdown","metadata":{"id":"44u2pruZSbMX"},"source":["Import tokenizer using the original vocab file:"]},{"cell_type":"code","metadata":{"id":"sm3lGfQb-1J8","executionInfo":{"status":"ok","timestamp":1619066499254,"user_tz":300,"elapsed":242,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n","do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n","tokenizer = bert.bert_tokenization.FullTokenizer(vocab_file, do_lower_case)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"5bQ-FXvtg_tY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619066634466,"user_tz":300,"elapsed":255,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"9be056e3-3538-4cdd-c71b-6d4412104f2b"},"source":["# The tokenizer converts a sentence to a sequence of tokens. Here's an example:\n","text = \"Here is an example sentence that I want to tokenize.\"\n","tokenized_text = tokenizer.tokenize(text)\n","print(tokenized_text)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["['here', 'is', 'an', 'example', 'sentence', 'that', 'i', 'want', 'to', 'token', '##ize', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AihvrFWcSzd6"},"source":["Now we tokenize every review in the IMDB dataset. This may take a minute to finish."]},{"cell_type":"code","metadata":{"id":"IeM20UdZ59i1","executionInfo":{"status":"ok","timestamp":1619066698552,"user_tz":300,"elapsed":40680,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["df['tokens'] = df[DATA_COLUMN].apply(lambda x : tokenizer.tokenize(x))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"X798BKV_Co71","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619066709915,"user_tz":300,"elapsed":334,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"b3ffc538-7cdb-4c0a-ad50-69d6a02ce2c5"},"source":["# An example of how the tokens for a review look like:\n","print(df['tokens'][2])"],"execution_count":23,"outputs":[{"output_type":"stream","text":["['hi', 'there', '.', 'i', 'watched', 'the', 'first', 'part', 'when', 'it', 'came', 'out', ',', 'and', 'i', 'don', \"'\", 't', 'remember', 'having', 'left', 'such', 'a', 'bad', 'impression', 'on', 'me', 'as', 'this', 'one', '.', 'first', ',', 'the', 'animation', 'is', 'chop', '##py', ',', 'wooden', ',', 'not', 'worked', 'on', ',', 'lacks', 'natural', '##ity', '-', 'i', 'understand', 'the', 'drawing', 'style', 'was', 'to', 'be', 'of', 'some', \"'\", 'at', '##lan', '##tea', '##n', \"'\", 'kind', ',', 'but', ',', 'it', 'could', 'be', 'done', 'with', 'the', 'usual', 'disney', 'fines', '##se', '.', '.', '.', 'see', '\"', 'tarzan', '\"', 'to', 'see', 'what', 'i', 'mean', '.', 'if', 'i', 'didn', \"'\", 't', 'see', 'the', 'disney', 'logo', 'in', 'the', 'beginning', ',', 'i', 'would', 'never', 'say', 'it', 'was', 'a', 'disney', 'movie', '.', 'second', ',', 'the', 'plot', 'was', 'more', 'like', 'a', 'pc', 'game', 'style', ',', 'like', 'a', 'good', 'old', 'quest', '.', 'not', 'that', 'it', 'was', 'bad', ',', 'but', 'it', 'lacked', 'a', 'story', 'that', 'binds', 'the', 'viewer', 'to', 'the', 'characters', 'and', 'their', 'goals', '.', 'it', 'was', 'inc', '##on', '##vin', '##cing', ',', 'at', 'least', '.', 'the', 'film', 'was', 'meant', 'for', 'children', ',', 'but', 'this', 'was', 'wa', '##aa', '##y', 'to', 'childish', 'at', 'times', '.', 'third', ',', 'the', 'music', '.', '.', '.', 'i', 'would', 'say', 'it', 'was', 'improper', ',', 'but', 'it', 'just', 'fits', 'the', 'whole', 'scene', 'with', 'the', 'plot', 'and', 'animation', '.', '.', '.', 'overall', ',', 'i', 'think', 'this', 'was', 'some', 'kind', 'of', 'an', 'amusement', ',', 'just', 'by', '-', 'the', '-', 'way', 'kind', 'of', 'project', 'by', 'several', 'apprentice', 'animator', '##s', ',', 'just', 'to', 'fill', 'in', 'the', 'count', 'for', 'disney', 'movies', '.', 'sorry', 'to', 'hear', 'that', 'from', 'myself', ',', 'a', 'big', 'disney', 'lover', '.', '.', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JhRfWt7S7lsE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619066726399,"user_tz":300,"elapsed":292,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"0dcc9704-3a0f-4025-ee27-5ca6d042077a"},"source":["# Some reviews are long. For example:\n","len(df['tokens'][0])"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["637"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"KQlSpWu_n4RY","collapsed":true,"executionInfo":{"status":"ok","timestamp":1619066749707,"user_tz":300,"elapsed":2611,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["# We now truncate any review with >=(MAX_SEQ_LENGTH-2) tokens.\n","# And add special tokens [CLS] and [SEP].\n","\n","def truncate_and_add(x, max_seq_length):\n","  a = [\"[CLS]\"] + x\n","  if len(a)>max_seq_length-1:\n","    a[max_seq_length-1] = \"[SEP]\"\n","    return a[:max_seq_length]\n","  else:\n","    return a + [\"[SEP]\"]\n","\n","df['tokens'] = df['tokens'].apply(lambda x : truncate_and_add(x, max_seq_length))"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ul1Y5afr5GCJ"},"source":["## Converting tokens to BERT input format"]},{"cell_type":"markdown","metadata":{"id":"y9PNZoFj3N6q"},"source":["We'll need to transform our data into a format BERT understands. This involves two steps. First, we create  `InputExamples` using the constructor provided in the BERT library.\n","\n","- `text_a` is the text we want to classify, which in this case, is the `review` field in our Dataframe. \n","- `text_b` is used if we're training a model to understand the relationship between sentences (i.e. is `text_b` a translation of `text_a`? Is `text_b` an answer to the question asked by `text_a`?). This doesn't apply to our task, so we can leave `text_b` blank.\n","- `label` is the target in supervised learning, which is `sentiment` in our example"]},{"cell_type":"markdown","metadata":{"id":"tU2OpvYrRFNf"},"source":["To use BERT embedding, we need to convert the tokens of each text input into the following format:\n"," - input token ids (tokenizer converts tokens using vocab file)\n"," - input masks (1 for useful tokens, 0 for padding)\n"," - segment ids (for 2 text training: 0 for the first one, 1 for the second one)\n"]},{"cell_type":"markdown","metadata":{"id":"BFDpzy1-STOh"},"source":["Define some functions for ease of preprocessing:"]},{"cell_type":"code","metadata":{"id":"e4Y_r3lmFO1E","executionInfo":{"status":"ok","timestamp":1619066972322,"user_tz":300,"elapsed":240,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["def get_ids(tokens, tokenizer, max_seq_length):\n","    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","    token_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n","    return np.array(token_ids, dtype=np.int32)\n","    \n","def get_masks(tokens, max_seq_length):\n","    token_masks = [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n","    return np.array(token_masks, dtype=np.int32)\n","\n","def get_segments(tokens, max_seq_length):\n","    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n","    segments = []\n","    current_segment_id = 0\n","    for token in tokens:\n","        segments.append(current_segment_id)\n","        if token == \"[SEP]\":\n","            current_segment_id = 1\n","    segments = segments + [0] * (max_seq_length - len(tokens))\n","    return np.array(segments, dtype=np.int32)\n"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_vqng48LuTs","executionInfo":{"status":"ok","timestamp":1619067007662,"user_tz":300,"elapsed":1448,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["df['ids'] = df['tokens'].apply(lambda x : get_ids(x, tokenizer, max_seq_length))\n","df['masks'] = df['tokens'].apply(lambda x : get_masks(x, max_seq_length))\n","df['segments'] = df['tokens'].apply(lambda x : get_segments(x, max_seq_length))"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"sb4GSTEkMgE3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619067068714,"user_tz":300,"elapsed":263,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"70eaba96-9151-4951-ed0c-fcdba8b32ee7"},"source":["# Let's see what the first movie review is now converted to:\n","df.iloc[0]"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["review       Congratulations to Christina Ricci for making ...\n","sentiment                                                    0\n","tokens       [[CLS], congratulations, to, christina, ric, #...\n","ids          [101, 23156, 2000, 12657, 26220, 6895, 2005, 2...\n","masks        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n","segments     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","Name: 0, dtype: object"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"nnaj5QdqleTS","executionInfo":{"status":"ok","timestamp":1619067154803,"user_tz":300,"elapsed":1229,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["# Now assemble the data as required by the definition of BERT inputs\n","n = df.shape[0]\n","all_ids = np.zeros(shape=(n,max_seq_length))\n","all_masks = np.zeros(shape=(n,max_seq_length)) \n","all_segments = np.zeros(shape=(n,max_seq_length))\n","i = 0\n","for index, row in df.iterrows():\n","  all_ids[i] = row.ids\n","  all_masks[i] = row.masks\n","  all_segments[i] = row.segments\n","  i += 1"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mi2mj4EUTi0X"},"source":["\n","## Using the pre-trained BERT model for sentence embedding"]},{"cell_type":"markdown","metadata":{"id":"u-RTA4QosF1H"},"source":["BERT converts each text input (in our example, a tokenized movie review) into the following.\n","* pooled output (also called pooled embedding, sentence embedding): this is a vector of size `768`, which represents the whole sentence.\n","* sequence outputs (also called sequence embeddings, word embeddings): this is a matrix of size `[max_seq_length, 768]`, where each token is now represented by a vector of size `768`.\n","\n","**For sentiment analysis, we only need the pooled output.**\n","\n","Similar to other deep learning models, BERT doesn't transform text one record at a time. Instead, BERT takes a batch of texts (e.g., a batch of movie reviews in our case) and convert them all at once. Thus the output shapes are:\n"," - pooled output of shape `[batch_size, 768]` with representations for the entire input sequences\n"," - sequence output of shape `[batch_size, max_seq_length, 768]`"]},{"cell_type":"markdown","metadata":{"id":"rH0bhH2S9cRs"},"source":["### A big data problem\n","\n","The output size from BERT can be huge. For example, in our dataset of 10000 movie reviews, where each review has a (truncated) length of 256, the total size of sequence embeddings is: `10000 * 256 * 768 * 4 ~= 8 Gigabyte`. This is too large to fit in Google Colab memory. So the following single-line code will likely trigger a \"ResourceExhaustedError\".\n","\n","`pool_embs, seq_embs = model.predict([all_ids,all_masks,all_segments])`\n","\n","Below is an workaround to avoid this bid data problem. We process our data 1000 records a time, i.e., set batch size at 1000. After each batch is processed, discard the sequence embeddings because we don't need them, and only save the pooled embeddings."]},{"cell_type":"code","metadata":{"id":"aag7a3JDd2kP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619068364456,"user_tz":300,"elapsed":210946,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"0b139e5e-3d9f-4cd4-9889-ff9b2f3d86cf"},"source":["pool_embs = np.zeros(shape=(n,768))\n","for i in np.arange(10):\n","  j = i*1000\n","  pool_embs[j:j+1000], seq_embs = model.predict([all_ids[j:j+1000],\n","                                                 all_masks[j:j+1000],\n","                                                 all_segments[j:j+1000]])\n","  print(f'{i+1}/10 of the data processed.')"],"execution_count":32,"outputs":[{"output_type":"stream","text":["1/10 of the data processed.\n","2/10 of the data processed.\n","3/10 of the data processed.\n","4/10 of the data processed.\n","5/10 of the data processed.\n","6/10 of the data processed.\n","7/10 of the data processed.\n","8/10 of the data processed.\n","9/10 of the data processed.\n","10/10 of the data processed.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DP43272orwSR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619068386351,"user_tz":300,"elapsed":248,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"8e0122a3-67d4-4928-bc52-95d0a2b90c71"},"source":["pool_embs.shape"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 768)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Ktdixe_2tfyx","executionInfo":{"status":"ok","timestamp":1619068387337,"user_tz":300,"elapsed":242,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"a6867f6e-ad47-4e4c-8add-3d69bb15023e"},"source":["pool_embs[0]"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.39288506, -0.38200733, -0.93822885,  0.39840695,  0.69078875,\n","        0.03995161, -0.41821665,  0.18299808, -0.86370063, -0.99983764,\n","       -0.42773068,  0.93359691,  0.93113583,  0.49542025,  0.44924992,\n","       -0.11027248,  0.42844871, -0.38838491,  0.29029307,  0.84075254,\n","        0.54123586,  0.99999559, -0.07752901,  0.22819921,  0.37814   ,\n","        0.980977  , -0.57791328,  0.73325461,  0.71572924,  0.70902973,\n","        0.18873926,  0.09612697, -0.96260536, -0.00846757, -0.97580045,\n","       -0.97711515,  0.22195676, -0.17037886,  0.27903038,  0.22599238,\n","       -0.49821594,  0.01342047,  0.99994415, -0.13116795,  0.58893472,\n","       -0.00399859, -0.99987859,  0.19726965, -0.51845223,  0.92321241,\n","        0.85511887,  0.95291692,  0.15571323,  0.2313665 ,  0.36370099,\n","       -0.61507559, -0.25904995,  0.01653609, -0.09299102, -0.35973966,\n","       -0.48011357,  0.27778593, -0.80756056, -0.66026044,  0.86174649,\n","        0.91938794, -0.15493563, -0.05324274,  0.09184919, -0.18632464,\n","        0.33738133,  0.14183338, -0.48335469, -0.78503758,  0.74169207,\n","        0.2071749 , -0.65312153,  0.99999976,  0.18373135, -0.90455121,\n","        0.95994091,  0.66115195,  0.4600895 , -0.18632913,  0.54386717,\n","       -0.99999923,  0.41058949,  0.04561965, -0.9511199 ,  0.00138747,\n","        0.50377125,  0.04980167,  0.93264323,  0.55787587, -0.40625283,\n","       -0.48266461, -0.19740599, -0.87285596, -0.12163279, -0.55328876,\n","        0.07218104, -0.12808019, -0.06924606, -0.09790841,  0.19472499,\n","       -0.35644561,  0.37885341,  0.66487998,  0.29604107,  0.47258145,\n","        0.49308693, -0.35459879,  0.31424278, -0.65539795,  0.4238387 ,\n","       -0.24393758, -0.92947495, -0.63036746, -0.95692348,  0.40654343,\n","       -0.1660112 , -0.03529828,  0.6756354 , -0.82932872,  0.28559113,\n","       -0.07916953, -0.92390823, -0.99999976, -0.31389791, -0.47670597,\n","       -0.063472  , -0.30428758, -0.86711997, -0.874951  ,  0.33342054,\n","        0.75679046, -0.02316225,  0.99961692, -0.18161966,  0.7458064 ,\n","       -0.09653509, -0.71438462,  0.6927368 , -0.33668703,  0.64418221,\n","       -0.82712287,  0.18304881,  0.10698522, -0.21325232,  0.11709194,\n","       -0.63459289, -0.05901045, -0.86746657, -0.59378147, -0.26760712,\n","        0.74617338, -0.61383396, -0.90142876, -0.2159709 ,  0.06026462,\n","        0.15590602,  0.3379586 ,  0.54915661,  0.18491708, -0.45442042,\n","        0.32924205, -0.17775132,  0.17516385, -0.34646514, -0.13187619,\n","        0.22752552, -0.33597681, -0.92428374, -0.93882751, -0.26255313,\n","        0.29607686,  0.90064037,  0.27112922,  0.12192719,  0.75101495,\n","       -0.22010304,  0.56257969, -0.82794231,  0.92292148,  0.19845526,\n","        0.16917346, -0.93176395,  0.73140675, -0.45230028,  0.29139367,\n","        0.16264515, -0.6571641 , -0.44566119,  0.06158988, -0.47066957,\n","       -0.07193507, -0.77710134,  0.18921924, -0.10112264, -0.25946981,\n","        0.03896945,  0.80370188, -0.04950486, -0.1877837 ,  0.48057321,\n","        0.4141036 , -0.41417801, -0.13598232, -0.01200953, -0.02758658,\n","       -0.09124959,  0.91212445, -0.77208579,  0.18925615, -0.65748608,\n","       -0.93139189, -0.31175599, -0.42668027, -0.14798506, -0.50082123,\n","        0.54616904, -0.87074178,  0.03679622,  0.03508792,  0.47978842,\n","       -0.39199373,  0.16183014, -0.31259146,  0.37847477, -0.14302863,\n","        0.98925167,  0.9647544 , -0.41869611, -0.85533983,  0.89733982,\n","       -0.9656263 , -0.58142561, -0.26896682, -0.11201736,  0.29071155,\n","       -0.48803979,  0.96358007,  0.86662555,  0.43913701, -0.57363892,\n","       -0.8764447 ,  0.11861423, -0.56046563, -0.13508865,  0.11875233,\n","        0.85378057,  0.55398172,  0.25113153,  0.49947807, -0.20617226,\n","       -0.4668147 , -0.99778587, -0.8097133 , -0.98545998,  0.31837064,\n","       -0.96754342,  0.88752842,  0.1471159 ,  0.7814973 , -0.34624159,\n","       -0.13626629, -0.7844339 , -0.17453285, -0.02834914,  0.59255022,\n","       -0.75063866, -0.25942439, -0.62612963, -0.73223799, -0.1890284 ,\n","       -0.05845995, -0.53802288, -0.10697119, -0.57107997,  0.48399439,\n","        0.43612871,  0.35116702, -0.92159462,  0.78533012,  0.99999976,\n","        0.86047715,  0.49500602, -0.19333905, -0.99993765, -0.95254135,\n","        0.99995518, -0.99164081, -0.99999958, -0.56598252, -0.42649776,\n","       -0.21435776, -0.99999976, -0.16966401,  0.2798427 , -0.63510185,\n","        0.70571566,  0.87159181,  0.07749765, -0.99999976,  0.70776069,\n","        0.67187744, -0.6293568 ,  0.90695024, -0.35093412,  0.90830338,\n","        0.35717472,  0.5140844 , -0.14942527,  0.46385989, -0.94025517,\n","       -0.14030492, -0.76023179, -0.84238446,  0.99949354,  0.04622278,\n","       -0.37844035, -0.51791537,  0.75409704,  0.20143406, -0.10232035,\n","       -0.80391967, -0.06612864,  0.16196659,  0.7158556 ,  0.07548255,\n","        0.12738682,  0.08484355,  0.00624817,  0.54730844, -0.44974011,\n","        0.59099501, -0.87090462,  0.15682697,  0.0859092 ,  0.18910235,\n","       -0.59861058, -0.89082998,  0.77587986, -0.19470119,  0.7528218 ,\n","        0.99999976,  0.86077851, -0.1040092 ,  0.44684166,  0.04078751,\n","       -0.85678643,  0.99999982,  0.7688123 , -0.9243958 , -0.60971904,\n","        0.57687718, -0.49626088, -0.56621689,  0.99702334, -0.0608817 ,\n","       -0.80860394, -0.26283938,  0.94127661, -0.96122462,  0.99823028,\n","       -0.303691  , -0.88563383,  0.79807544,  0.76691657, -0.05325643,\n","       -0.53805351, -0.00135142, -0.58299208,  0.16779497, -0.2298089 ,\n","        0.44082776, -0.04052632,  0.09614202,  0.54274327,  0.72342986,\n","       -0.61724299,  0.05948705, -0.58819246, -0.18112093,  0.95277745,\n","        0.31788692, -0.19459201, -0.20160843, -0.16326295, -0.93010867,\n","       -0.8445586 ,  0.70163751,  0.99999976, -0.28786853,  0.85360497,\n","       -0.2395115 ,  0.0400917 , -0.07175025,  0.41516647,  0.51187426,\n","       -0.00643034, -0.71810615,  0.83087671, -0.2396085 , -0.97139823,\n","       -0.20856535, -0.02947373,  0.07800873,  0.9990477 ,  0.30935231,\n","        0.15409963,  0.55448282,  0.97984415, -0.15835693, -0.36543491,\n","        0.86738616,  0.92213714, -0.11724646,  0.60714698, -0.2574006 ,\n","       -0.83610457, -0.10049814, -0.5508076 , -0.12560001, -0.85660493,\n","        0.19921876, -0.77374011,  0.79851204,  0.8951261 ,  0.22781722,\n","        0.1433152 ,  0.73857492,  0.99999976, -0.98447007, -0.04261801,\n","        0.95609939, -0.51995641, -0.99994552, -0.08378334, -0.31786129,\n","        0.12554777, -0.87883592, -0.07912176,  0.08071566, -0.83469093,\n","        0.72436666,  0.82410461, -0.04297113, -0.8983838 , -0.84485424,\n","       -0.47314778, -0.06252442, -0.99183244, -0.12360846, -0.23067084,\n","        0.56086421, -0.27874026, -0.66076326, -0.19779442, -0.23503958,\n","        0.31937516, -0.15514544,  0.64553571,  0.83356696,  0.85348952,\n","       -0.90448046, -0.20944825, -0.03853134, -0.12114847,  0.33201367,\n","       -0.41498533, -0.90784395,  0.08806742,  0.99999976, -0.66867536,\n","        0.93658453,  0.06446716,  0.05523424, -0.24112357,  0.12956585,\n","        0.95159519,  0.14863317, -0.73579842, -0.85027409,  0.97783303,\n","       -0.23803951,  0.42496252,  0.84075862,  0.7761209 ,  0.46222788,\n","        0.8523609 ,  0.14876002,  0.21554056, -0.18397471,  0.13992226,\n","        0.04354667, -0.36013857, -0.31160271, -0.10737265, -0.33554322,\n","        0.93190372,  0.99999976,  0.12009152,  0.60593969, -0.94425571,\n","       -0.7754795 , -0.2501837 ,  0.9999997 ,  0.64327627, -0.24031909,\n","        0.6519444 ,  0.33833763,  0.04677141, -0.51073557, -0.0545617 ,\n","        0.01123318,  0.01231249, -0.12934799,  0.82909989, -0.50297421,\n","       -0.87005603, -0.1335638 ,  0.15516037, -0.80991381,  0.99997073,\n","       -0.50337559, -0.1149184 , -0.1462791 , -0.29431304, -0.98833001,\n","       -0.14462201, -0.88159645, -0.10030935,  0.17240259,  0.79108173,\n","       -0.05794985, -0.58703417, -0.47472176,  0.86750078,  0.64161515,\n","       -0.88115126, -0.81325543,  0.80861515, -0.82912236,  0.50064725,\n","        0.99999297,  0.336831  ,  0.12243527, -0.08535212, -0.06909104,\n","        0.29302108, -0.31150758,  0.16766943, -0.74560338, -0.34171507,\n","       -0.04051552,  0.20513137, -0.12443682, -0.78360552, -0.17315789,\n","       -0.00486134, -0.47511575, -0.55285686,  0.01586444,  0.29067475,\n","        0.46276158, -0.14046435,  0.04072932,  0.00556336,  0.15202607,\n","       -0.72559643, -0.31657574, -0.31549585, -0.9999975 ,  0.22453277,\n","       -0.99999976,  0.72972733,  0.24987844, -0.0800612 ,  0.56773776,\n","        0.89560211,  0.84634399, -0.06658045, -0.8814984 ,  0.3162941 ,\n","        0.42297593, -0.14001073,  0.14528401,  0.014733  ,  0.20496252,\n","        0.14809959,  0.13483131, -0.73605388,  0.58032864, -0.16864726,\n","        0.99999976, -0.07957947, -0.23138355, -0.08871496,  0.08045279,\n","       -0.10462511,  0.99999976,  0.53427213, -0.81527919,  0.17412062,\n","       -0.60759532, -0.45939156,  0.32142732, -0.13949305, -0.65479028,\n","       -0.93878478,  0.49873522, -0.44116098, -0.69843191,  0.56162941,\n","       -0.02743448, -0.44326696, -0.03522645,  0.91393673,  0.91958702,\n","        0.59496355, -0.02409506, -0.95472491, -0.68087113,  0.88669544,\n","        0.26739687, -0.66064352, -0.07155045,  0.99999976,  0.12392849,\n","       -0.58682007, -0.0960503 , -0.65881956,  0.07087083, -0.63909274,\n","        0.10158071, -0.03441507,  0.78975856, -0.18107022,  0.75082773,\n","       -0.87637067, -0.14770417, -0.33439097, -0.64067525,  0.21556109,\n","       -0.61935693, -0.95861107, -0.94422579,  0.58870226, -0.15342319,\n","       -0.06464113,  0.30306512,  0.0093616 ,  0.26437771,  0.23107778,\n","       -0.99999976,  0.81179887,  0.21641576,  0.90875578,  0.7278325 ,\n","        0.70026261,  0.63686699,  0.31513542, -0.90581214, -0.07246136,\n","       -0.14720394, -0.11826936,  0.11185953,  0.60019082,  0.39063454,\n","        0.18712579, -0.33130547, -0.71876824, -0.86290324, -0.98857802,\n","       -0.96107197,  0.2821196 , -0.74323362,  0.34180254,  0.8439461 ,\n","        0.07713537,  0.07164496, -0.45611641, -0.86489832, -0.63285637,\n","        0.53131115, -0.37397039, -0.25054595,  0.31244689,  0.54725379,\n","        0.29705229,  0.93500578, -0.90289265, -0.18681793, -0.82862884,\n","        0.42873615,  0.96797836, -0.8923533 ,  0.01117166,  0.45532802,\n","       -0.1245173 ,  0.2464316 , -0.26096529, -0.13327333,  0.78510433,\n","       -0.09948715,  0.2951268 , -0.17219737,  0.10626489, -0.21120326,\n","       -0.06032407, -0.52123916, -0.5228731 ,  0.61966938, -0.27154976,\n","        0.4395889 ,  0.88513952,  0.00844223, -0.27207783, -0.0576838 ,\n","       -0.7329461 , -0.7015295 , -0.32179084,  0.26127863, -0.10853211,\n","        0.6423105 , -0.32246   ,  0.98833776,  0.0751942 , -0.22515419,\n","       -0.23454024, -0.32039228,  0.48667711, -0.76309264, -0.33555612,\n","       -0.2503778 ,  0.44819301,  0.03369965,  0.99999607, -0.7788747 ,\n","       -0.86227649, -0.56015092, -0.22256736,  0.21450353,  0.02894854,\n","       -0.99999976,  0.17605093, -0.69732505,  0.74725842, -0.64559549,\n","        0.8109768 , -0.33919823, -0.55121362, -0.17650358,  0.83931941,\n","        0.86437482, -0.22396785, -0.34721974,  0.54383481, -0.56437033,\n","        0.95668334,  0.42947495,  0.18110055,  0.19911219,  0.63525522,\n","       -0.81152546, -0.43574175,  0.39094841])"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"r5HcG7LpAAZE"},"source":["## Assembling a new dataset with features extracted by BERT\n","\n","For each text, the corresponding pooled output is a vector of 768 numbers that summaries this whole text. We can now treat these 768 numbers as features extracted by BERT. Let's assemble a new DataFrame with these figures and the sentiment data."]},{"cell_type":"code","metadata":{"id":"jxzOuyZd_O92","colab":{"base_uri":"https://localhost:8080/","height":247},"executionInfo":{"status":"ok","timestamp":1619068398340,"user_tz":300,"elapsed":419,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"6f20a4a6-16f3-4d59-9479-425f5eaa569c"},"source":["feature_df = pd.DataFrame(pool_embs)\n","feature_df.head()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>...</th>\n","      <th>728</th>\n","      <th>729</th>\n","      <th>730</th>\n","      <th>731</th>\n","      <th>732</th>\n","      <th>733</th>\n","      <th>734</th>\n","      <th>735</th>\n","      <th>736</th>\n","      <th>737</th>\n","      <th>738</th>\n","      <th>739</th>\n","      <th>740</th>\n","      <th>741</th>\n","      <th>742</th>\n","      <th>743</th>\n","      <th>744</th>\n","      <th>745</th>\n","      <th>746</th>\n","      <th>747</th>\n","      <th>748</th>\n","      <th>749</th>\n","      <th>750</th>\n","      <th>751</th>\n","      <th>752</th>\n","      <th>753</th>\n","      <th>754</th>\n","      <th>755</th>\n","      <th>756</th>\n","      <th>757</th>\n","      <th>758</th>\n","      <th>759</th>\n","      <th>760</th>\n","      <th>761</th>\n","      <th>762</th>\n","      <th>763</th>\n","      <th>764</th>\n","      <th>765</th>\n","      <th>766</th>\n","      <th>767</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.392885</td>\n","      <td>-0.382007</td>\n","      <td>-0.938229</td>\n","      <td>0.398407</td>\n","      <td>0.690789</td>\n","      <td>0.039952</td>\n","      <td>-0.418217</td>\n","      <td>0.182998</td>\n","      <td>-0.863701</td>\n","      <td>-0.999838</td>\n","      <td>-0.427731</td>\n","      <td>0.933597</td>\n","      <td>0.931136</td>\n","      <td>0.495420</td>\n","      <td>0.449250</td>\n","      <td>-0.110272</td>\n","      <td>0.428449</td>\n","      <td>-0.388385</td>\n","      <td>0.290293</td>\n","      <td>0.840753</td>\n","      <td>0.541236</td>\n","      <td>0.999996</td>\n","      <td>-0.077529</td>\n","      <td>0.228199</td>\n","      <td>0.378140</td>\n","      <td>0.980977</td>\n","      <td>-0.577913</td>\n","      <td>0.733255</td>\n","      <td>0.715729</td>\n","      <td>0.709030</td>\n","      <td>0.188739</td>\n","      <td>0.096127</td>\n","      <td>-0.962605</td>\n","      <td>-0.008468</td>\n","      <td>-0.975800</td>\n","      <td>-0.977115</td>\n","      <td>0.221957</td>\n","      <td>-0.170379</td>\n","      <td>0.279030</td>\n","      <td>0.225992</td>\n","      <td>...</td>\n","      <td>0.075194</td>\n","      <td>-0.225154</td>\n","      <td>-0.234540</td>\n","      <td>-0.320392</td>\n","      <td>0.486677</td>\n","      <td>-0.763093</td>\n","      <td>-0.335556</td>\n","      <td>-0.250378</td>\n","      <td>0.448193</td>\n","      <td>0.033700</td>\n","      <td>0.999996</td>\n","      <td>-0.778875</td>\n","      <td>-0.862276</td>\n","      <td>-0.560151</td>\n","      <td>-0.222567</td>\n","      <td>0.214504</td>\n","      <td>0.028949</td>\n","      <td>-1.0</td>\n","      <td>0.176051</td>\n","      <td>-0.697325</td>\n","      <td>0.747258</td>\n","      <td>-0.645595</td>\n","      <td>0.810977</td>\n","      <td>-0.339198</td>\n","      <td>-0.551214</td>\n","      <td>-0.176504</td>\n","      <td>0.839319</td>\n","      <td>0.864375</td>\n","      <td>-0.223968</td>\n","      <td>-0.347220</td>\n","      <td>0.543835</td>\n","      <td>-0.564370</td>\n","      <td>0.956683</td>\n","      <td>0.429475</td>\n","      <td>0.181101</td>\n","      <td>0.199112</td>\n","      <td>0.635255</td>\n","      <td>-0.811525</td>\n","      <td>-0.435742</td>\n","      <td>0.390948</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.776412</td>\n","      <td>-0.479143</td>\n","      <td>-0.966163</td>\n","      <td>0.483075</td>\n","      <td>0.735439</td>\n","      <td>0.110490</td>\n","      <td>0.520940</td>\n","      <td>0.373213</td>\n","      <td>-0.884016</td>\n","      <td>-0.999994</td>\n","      <td>-0.464932</td>\n","      <td>0.939287</td>\n","      <td>0.963481</td>\n","      <td>0.724542</td>\n","      <td>0.811432</td>\n","      <td>-0.593823</td>\n","      <td>0.150257</td>\n","      <td>-0.514505</td>\n","      <td>0.174578</td>\n","      <td>0.545818</td>\n","      <td>0.727452</td>\n","      <td>1.000000</td>\n","      <td>-0.179627</td>\n","      <td>0.383355</td>\n","      <td>0.363103</td>\n","      <td>0.986535</td>\n","      <td>-0.615079</td>\n","      <td>0.885119</td>\n","      <td>0.937005</td>\n","      <td>0.822033</td>\n","      <td>-0.332285</td>\n","      <td>0.308077</td>\n","      <td>-0.981316</td>\n","      <td>-0.081927</td>\n","      <td>-0.981529</td>\n","      <td>-0.991082</td>\n","      <td>0.470549</td>\n","      <td>-0.432180</td>\n","      <td>-0.033664</td>\n","      <td>-0.094756</td>\n","      <td>...</td>\n","      <td>0.417558</td>\n","      <td>-0.388657</td>\n","      <td>-0.325882</td>\n","      <td>-0.581247</td>\n","      <td>0.735591</td>\n","      <td>-0.750473</td>\n","      <td>-0.612798</td>\n","      <td>-0.581870</td>\n","      <td>0.756416</td>\n","      <td>0.273035</td>\n","      <td>1.000000</td>\n","      <td>-0.854301</td>\n","      <td>-0.946476</td>\n","      <td>-0.443064</td>\n","      <td>-0.439860</td>\n","      <td>0.480186</td>\n","      <td>-0.488955</td>\n","      <td>-1.0</td>\n","      <td>0.374267</td>\n","      <td>-0.578545</td>\n","      <td>0.889650</td>\n","      <td>-0.754009</td>\n","      <td>0.912782</td>\n","      <td>-0.667797</td>\n","      <td>-0.892207</td>\n","      <td>-0.399767</td>\n","      <td>0.878065</td>\n","      <td>0.866837</td>\n","      <td>-0.459350</td>\n","      <td>-0.521142</td>\n","      <td>0.688332</td>\n","      <td>-0.457478</td>\n","      <td>0.979939</td>\n","      <td>0.630784</td>\n","      <td>-0.082554</td>\n","      <td>-0.106779</td>\n","      <td>0.773375</td>\n","      <td>-0.826193</td>\n","      <td>-0.651949</td>\n","      <td>0.812310</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.532591</td>\n","      <td>-0.387242</td>\n","      <td>-0.952996</td>\n","      <td>0.497544</td>\n","      <td>0.763823</td>\n","      <td>-0.018741</td>\n","      <td>-0.007338</td>\n","      <td>0.197360</td>\n","      <td>-0.838852</td>\n","      <td>-0.999875</td>\n","      <td>-0.567266</td>\n","      <td>0.950285</td>\n","      <td>0.938886</td>\n","      <td>0.641195</td>\n","      <td>0.643097</td>\n","      <td>-0.359462</td>\n","      <td>0.314580</td>\n","      <td>-0.562200</td>\n","      <td>0.267115</td>\n","      <td>0.781857</td>\n","      <td>0.489104</td>\n","      <td>0.999998</td>\n","      <td>-0.152318</td>\n","      <td>0.361618</td>\n","      <td>0.392454</td>\n","      <td>0.979932</td>\n","      <td>-0.697706</td>\n","      <td>0.840310</td>\n","      <td>0.802404</td>\n","      <td>0.710169</td>\n","      <td>-0.183059</td>\n","      <td>0.168304</td>\n","      <td>-0.967066</td>\n","      <td>-0.194827</td>\n","      <td>-0.971231</td>\n","      <td>-0.980333</td>\n","      <td>0.359173</td>\n","      <td>-0.262316</td>\n","      <td>0.103260</td>\n","      <td>0.168209</td>\n","      <td>...</td>\n","      <td>0.361302</td>\n","      <td>-0.312310</td>\n","      <td>-0.210683</td>\n","      <td>-0.299113</td>\n","      <td>0.486185</td>\n","      <td>-0.736889</td>\n","      <td>-0.539592</td>\n","      <td>-0.343858</td>\n","      <td>0.490780</td>\n","      <td>0.182760</td>\n","      <td>0.999998</td>\n","      <td>-0.900402</td>\n","      <td>-0.927199</td>\n","      <td>-0.500910</td>\n","      <td>-0.391939</td>\n","      <td>0.445694</td>\n","      <td>-0.261197</td>\n","      <td>-1.0</td>\n","      <td>0.214347</td>\n","      <td>-0.733179</td>\n","      <td>0.861573</td>\n","      <td>-0.735236</td>\n","      <td>0.921946</td>\n","      <td>-0.400561</td>\n","      <td>-0.834726</td>\n","      <td>-0.252357</td>\n","      <td>0.867712</td>\n","      <td>0.881082</td>\n","      <td>-0.290217</td>\n","      <td>-0.187555</td>\n","      <td>0.616574</td>\n","      <td>-0.203550</td>\n","      <td>0.968841</td>\n","      <td>0.482654</td>\n","      <td>-0.517320</td>\n","      <td>-0.143238</td>\n","      <td>0.614655</td>\n","      <td>-0.894548</td>\n","      <td>-0.570303</td>\n","      <td>0.546067</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.594817</td>\n","      <td>-0.403342</td>\n","      <td>-0.953941</td>\n","      <td>0.517494</td>\n","      <td>0.841254</td>\n","      <td>-0.026739</td>\n","      <td>0.022725</td>\n","      <td>0.156407</td>\n","      <td>-0.892972</td>\n","      <td>-0.999742</td>\n","      <td>-0.608055</td>\n","      <td>0.945132</td>\n","      <td>0.939643</td>\n","      <td>0.599365</td>\n","      <td>0.584011</td>\n","      <td>-0.390083</td>\n","      <td>0.086453</td>\n","      <td>-0.428089</td>\n","      <td>0.170764</td>\n","      <td>0.626081</td>\n","      <td>0.425075</td>\n","      <td>0.999995</td>\n","      <td>-0.038928</td>\n","      <td>0.245449</td>\n","      <td>0.258321</td>\n","      <td>0.986758</td>\n","      <td>-0.605088</td>\n","      <td>0.781417</td>\n","      <td>0.805887</td>\n","      <td>0.589119</td>\n","      <td>-0.073113</td>\n","      <td>0.118716</td>\n","      <td>-0.970241</td>\n","      <td>-0.125292</td>\n","      <td>-0.944507</td>\n","      <td>-0.977190</td>\n","      <td>0.241200</td>\n","      <td>-0.269667</td>\n","      <td>0.189351</td>\n","      <td>0.181290</td>\n","      <td>...</td>\n","      <td>0.208609</td>\n","      <td>-0.227695</td>\n","      <td>-0.219675</td>\n","      <td>-0.348739</td>\n","      <td>0.594702</td>\n","      <td>-0.777287</td>\n","      <td>-0.378595</td>\n","      <td>-0.372857</td>\n","      <td>0.435433</td>\n","      <td>0.070352</td>\n","      <td>0.999995</td>\n","      <td>-0.859133</td>\n","      <td>-0.928382</td>\n","      <td>-0.434548</td>\n","      <td>-0.349002</td>\n","      <td>0.312163</td>\n","      <td>-0.296398</td>\n","      <td>-1.0</td>\n","      <td>0.090986</td>\n","      <td>-0.733399</td>\n","      <td>0.795553</td>\n","      <td>-0.807325</td>\n","      <td>0.921434</td>\n","      <td>-0.501338</td>\n","      <td>-0.788751</td>\n","      <td>-0.087494</td>\n","      <td>0.801062</td>\n","      <td>0.885823</td>\n","      <td>-0.373333</td>\n","      <td>-0.343366</td>\n","      <td>0.600299</td>\n","      <td>-0.545601</td>\n","      <td>0.980657</td>\n","      <td>0.575146</td>\n","      <td>0.135790</td>\n","      <td>0.120160</td>\n","      <td>0.696775</td>\n","      <td>-0.911567</td>\n","      <td>-0.503772</td>\n","      <td>0.692356</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.410833</td>\n","      <td>-0.506333</td>\n","      <td>-0.995662</td>\n","      <td>0.530960</td>\n","      <td>0.960250</td>\n","      <td>-0.236363</td>\n","      <td>-0.282453</td>\n","      <td>0.447984</td>\n","      <td>-0.960383</td>\n","      <td>-0.999265</td>\n","      <td>-0.781264</td>\n","      <td>0.974797</td>\n","      <td>0.893978</td>\n","      <td>0.797164</td>\n","      <td>0.428669</td>\n","      <td>-0.476356</td>\n","      <td>0.003985</td>\n","      <td>-0.647214</td>\n","      <td>0.304032</td>\n","      <td>0.872063</td>\n","      <td>0.531742</td>\n","      <td>1.000000</td>\n","      <td>-0.455619</td>\n","      <td>0.363179</td>\n","      <td>0.364398</td>\n","      <td>0.995275</td>\n","      <td>-0.730364</td>\n","      <td>0.680403</td>\n","      <td>0.570509</td>\n","      <td>0.578997</td>\n","      <td>0.228405</td>\n","      <td>0.039234</td>\n","      <td>-0.953021</td>\n","      <td>-0.277550</td>\n","      <td>-0.998966</td>\n","      <td>-0.962857</td>\n","      <td>0.441451</td>\n","      <td>-0.007218</td>\n","      <td>-0.027191</td>\n","      <td>0.172031</td>\n","      <td>...</td>\n","      <td>0.726821</td>\n","      <td>-0.360532</td>\n","      <td>-0.351759</td>\n","      <td>-0.493682</td>\n","      <td>0.436126</td>\n","      <td>-0.871435</td>\n","      <td>-0.586574</td>\n","      <td>-0.393124</td>\n","      <td>0.491337</td>\n","      <td>0.285180</td>\n","      <td>1.000000</td>\n","      <td>-0.982884</td>\n","      <td>-0.977736</td>\n","      <td>-0.594445</td>\n","      <td>-0.442828</td>\n","      <td>0.509552</td>\n","      <td>-0.372019</td>\n","      <td>-1.0</td>\n","      <td>0.203671</td>\n","      <td>-0.767502</td>\n","      <td>0.953264</td>\n","      <td>-0.941762</td>\n","      <td>0.990971</td>\n","      <td>-0.633268</td>\n","      <td>-0.637323</td>\n","      <td>-0.443813</td>\n","      <td>0.915532</td>\n","      <td>0.961086</td>\n","      <td>-0.354065</td>\n","      <td>-0.199670</td>\n","      <td>0.555582</td>\n","      <td>-0.100036</td>\n","      <td>0.997626</td>\n","      <td>0.311818</td>\n","      <td>-0.217166</td>\n","      <td>-0.397853</td>\n","      <td>0.669593</td>\n","      <td>-0.970973</td>\n","      <td>-0.529365</td>\n","      <td>0.628633</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 768 columns</p>\n","</div>"],"text/plain":["        0         1         2    ...       765       766       767\n","0 -0.392885 -0.382007 -0.938229  ... -0.811525 -0.435742  0.390948\n","1 -0.776412 -0.479143 -0.966163  ... -0.826193 -0.651949  0.812310\n","2 -0.532591 -0.387242 -0.952996  ... -0.894548 -0.570303  0.546067\n","3 -0.594817 -0.403342 -0.953941  ... -0.911567 -0.503772  0.692356\n","4 -0.410833 -0.506333 -0.995662  ... -0.970973 -0.529365  0.628633\n","\n","[5 rows x 768 columns]"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"pZi0XUqcrRay","collapsed":true,"colab":{"base_uri":"https://localhost:8080/","height":247},"executionInfo":{"status":"ok","timestamp":1619068400874,"user_tz":300,"elapsed":344,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"3b14970f-dad8-4c4d-b06b-aeb053df9ee8"},"source":["feature_df['sentiment'] = df['sentiment']\n","feature_df.head()"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>...</th>\n","      <th>729</th>\n","      <th>730</th>\n","      <th>731</th>\n","      <th>732</th>\n","      <th>733</th>\n","      <th>734</th>\n","      <th>735</th>\n","      <th>736</th>\n","      <th>737</th>\n","      <th>738</th>\n","      <th>739</th>\n","      <th>740</th>\n","      <th>741</th>\n","      <th>742</th>\n","      <th>743</th>\n","      <th>744</th>\n","      <th>745</th>\n","      <th>746</th>\n","      <th>747</th>\n","      <th>748</th>\n","      <th>749</th>\n","      <th>750</th>\n","      <th>751</th>\n","      <th>752</th>\n","      <th>753</th>\n","      <th>754</th>\n","      <th>755</th>\n","      <th>756</th>\n","      <th>757</th>\n","      <th>758</th>\n","      <th>759</th>\n","      <th>760</th>\n","      <th>761</th>\n","      <th>762</th>\n","      <th>763</th>\n","      <th>764</th>\n","      <th>765</th>\n","      <th>766</th>\n","      <th>767</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.392885</td>\n","      <td>-0.382007</td>\n","      <td>-0.938229</td>\n","      <td>0.398407</td>\n","      <td>0.690789</td>\n","      <td>0.039952</td>\n","      <td>-0.418217</td>\n","      <td>0.182998</td>\n","      <td>-0.863701</td>\n","      <td>-0.999838</td>\n","      <td>-0.427731</td>\n","      <td>0.933597</td>\n","      <td>0.931136</td>\n","      <td>0.495420</td>\n","      <td>0.449250</td>\n","      <td>-0.110272</td>\n","      <td>0.428449</td>\n","      <td>-0.388385</td>\n","      <td>0.290293</td>\n","      <td>0.840753</td>\n","      <td>0.541236</td>\n","      <td>0.999996</td>\n","      <td>-0.077529</td>\n","      <td>0.228199</td>\n","      <td>0.378140</td>\n","      <td>0.980977</td>\n","      <td>-0.577913</td>\n","      <td>0.733255</td>\n","      <td>0.715729</td>\n","      <td>0.709030</td>\n","      <td>0.188739</td>\n","      <td>0.096127</td>\n","      <td>-0.962605</td>\n","      <td>-0.008468</td>\n","      <td>-0.975800</td>\n","      <td>-0.977115</td>\n","      <td>0.221957</td>\n","      <td>-0.170379</td>\n","      <td>0.279030</td>\n","      <td>0.225992</td>\n","      <td>...</td>\n","      <td>-0.225154</td>\n","      <td>-0.234540</td>\n","      <td>-0.320392</td>\n","      <td>0.486677</td>\n","      <td>-0.763093</td>\n","      <td>-0.335556</td>\n","      <td>-0.250378</td>\n","      <td>0.448193</td>\n","      <td>0.033700</td>\n","      <td>0.999996</td>\n","      <td>-0.778875</td>\n","      <td>-0.862276</td>\n","      <td>-0.560151</td>\n","      <td>-0.222567</td>\n","      <td>0.214504</td>\n","      <td>0.028949</td>\n","      <td>-1.0</td>\n","      <td>0.176051</td>\n","      <td>-0.697325</td>\n","      <td>0.747258</td>\n","      <td>-0.645595</td>\n","      <td>0.810977</td>\n","      <td>-0.339198</td>\n","      <td>-0.551214</td>\n","      <td>-0.176504</td>\n","      <td>0.839319</td>\n","      <td>0.864375</td>\n","      <td>-0.223968</td>\n","      <td>-0.347220</td>\n","      <td>0.543835</td>\n","      <td>-0.564370</td>\n","      <td>0.956683</td>\n","      <td>0.429475</td>\n","      <td>0.181101</td>\n","      <td>0.199112</td>\n","      <td>0.635255</td>\n","      <td>-0.811525</td>\n","      <td>-0.435742</td>\n","      <td>0.390948</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.776412</td>\n","      <td>-0.479143</td>\n","      <td>-0.966163</td>\n","      <td>0.483075</td>\n","      <td>0.735439</td>\n","      <td>0.110490</td>\n","      <td>0.520940</td>\n","      <td>0.373213</td>\n","      <td>-0.884016</td>\n","      <td>-0.999994</td>\n","      <td>-0.464932</td>\n","      <td>0.939287</td>\n","      <td>0.963481</td>\n","      <td>0.724542</td>\n","      <td>0.811432</td>\n","      <td>-0.593823</td>\n","      <td>0.150257</td>\n","      <td>-0.514505</td>\n","      <td>0.174578</td>\n","      <td>0.545818</td>\n","      <td>0.727452</td>\n","      <td>1.000000</td>\n","      <td>-0.179627</td>\n","      <td>0.383355</td>\n","      <td>0.363103</td>\n","      <td>0.986535</td>\n","      <td>-0.615079</td>\n","      <td>0.885119</td>\n","      <td>0.937005</td>\n","      <td>0.822033</td>\n","      <td>-0.332285</td>\n","      <td>0.308077</td>\n","      <td>-0.981316</td>\n","      <td>-0.081927</td>\n","      <td>-0.981529</td>\n","      <td>-0.991082</td>\n","      <td>0.470549</td>\n","      <td>-0.432180</td>\n","      <td>-0.033664</td>\n","      <td>-0.094756</td>\n","      <td>...</td>\n","      <td>-0.388657</td>\n","      <td>-0.325882</td>\n","      <td>-0.581247</td>\n","      <td>0.735591</td>\n","      <td>-0.750473</td>\n","      <td>-0.612798</td>\n","      <td>-0.581870</td>\n","      <td>0.756416</td>\n","      <td>0.273035</td>\n","      <td>1.000000</td>\n","      <td>-0.854301</td>\n","      <td>-0.946476</td>\n","      <td>-0.443064</td>\n","      <td>-0.439860</td>\n","      <td>0.480186</td>\n","      <td>-0.488955</td>\n","      <td>-1.0</td>\n","      <td>0.374267</td>\n","      <td>-0.578545</td>\n","      <td>0.889650</td>\n","      <td>-0.754009</td>\n","      <td>0.912782</td>\n","      <td>-0.667797</td>\n","      <td>-0.892207</td>\n","      <td>-0.399767</td>\n","      <td>0.878065</td>\n","      <td>0.866837</td>\n","      <td>-0.459350</td>\n","      <td>-0.521142</td>\n","      <td>0.688332</td>\n","      <td>-0.457478</td>\n","      <td>0.979939</td>\n","      <td>0.630784</td>\n","      <td>-0.082554</td>\n","      <td>-0.106779</td>\n","      <td>0.773375</td>\n","      <td>-0.826193</td>\n","      <td>-0.651949</td>\n","      <td>0.812310</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.532591</td>\n","      <td>-0.387242</td>\n","      <td>-0.952996</td>\n","      <td>0.497544</td>\n","      <td>0.763823</td>\n","      <td>-0.018741</td>\n","      <td>-0.007338</td>\n","      <td>0.197360</td>\n","      <td>-0.838852</td>\n","      <td>-0.999875</td>\n","      <td>-0.567266</td>\n","      <td>0.950285</td>\n","      <td>0.938886</td>\n","      <td>0.641195</td>\n","      <td>0.643097</td>\n","      <td>-0.359462</td>\n","      <td>0.314580</td>\n","      <td>-0.562200</td>\n","      <td>0.267115</td>\n","      <td>0.781857</td>\n","      <td>0.489104</td>\n","      <td>0.999998</td>\n","      <td>-0.152318</td>\n","      <td>0.361618</td>\n","      <td>0.392454</td>\n","      <td>0.979932</td>\n","      <td>-0.697706</td>\n","      <td>0.840310</td>\n","      <td>0.802404</td>\n","      <td>0.710169</td>\n","      <td>-0.183059</td>\n","      <td>0.168304</td>\n","      <td>-0.967066</td>\n","      <td>-0.194827</td>\n","      <td>-0.971231</td>\n","      <td>-0.980333</td>\n","      <td>0.359173</td>\n","      <td>-0.262316</td>\n","      <td>0.103260</td>\n","      <td>0.168209</td>\n","      <td>...</td>\n","      <td>-0.312310</td>\n","      <td>-0.210683</td>\n","      <td>-0.299113</td>\n","      <td>0.486185</td>\n","      <td>-0.736889</td>\n","      <td>-0.539592</td>\n","      <td>-0.343858</td>\n","      <td>0.490780</td>\n","      <td>0.182760</td>\n","      <td>0.999998</td>\n","      <td>-0.900402</td>\n","      <td>-0.927199</td>\n","      <td>-0.500910</td>\n","      <td>-0.391939</td>\n","      <td>0.445694</td>\n","      <td>-0.261197</td>\n","      <td>-1.0</td>\n","      <td>0.214347</td>\n","      <td>-0.733179</td>\n","      <td>0.861573</td>\n","      <td>-0.735236</td>\n","      <td>0.921946</td>\n","      <td>-0.400561</td>\n","      <td>-0.834726</td>\n","      <td>-0.252357</td>\n","      <td>0.867712</td>\n","      <td>0.881082</td>\n","      <td>-0.290217</td>\n","      <td>-0.187555</td>\n","      <td>0.616574</td>\n","      <td>-0.203550</td>\n","      <td>0.968841</td>\n","      <td>0.482654</td>\n","      <td>-0.517320</td>\n","      <td>-0.143238</td>\n","      <td>0.614655</td>\n","      <td>-0.894548</td>\n","      <td>-0.570303</td>\n","      <td>0.546067</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.594817</td>\n","      <td>-0.403342</td>\n","      <td>-0.953941</td>\n","      <td>0.517494</td>\n","      <td>0.841254</td>\n","      <td>-0.026739</td>\n","      <td>0.022725</td>\n","      <td>0.156407</td>\n","      <td>-0.892972</td>\n","      <td>-0.999742</td>\n","      <td>-0.608055</td>\n","      <td>0.945132</td>\n","      <td>0.939643</td>\n","      <td>0.599365</td>\n","      <td>0.584011</td>\n","      <td>-0.390083</td>\n","      <td>0.086453</td>\n","      <td>-0.428089</td>\n","      <td>0.170764</td>\n","      <td>0.626081</td>\n","      <td>0.425075</td>\n","      <td>0.999995</td>\n","      <td>-0.038928</td>\n","      <td>0.245449</td>\n","      <td>0.258321</td>\n","      <td>0.986758</td>\n","      <td>-0.605088</td>\n","      <td>0.781417</td>\n","      <td>0.805887</td>\n","      <td>0.589119</td>\n","      <td>-0.073113</td>\n","      <td>0.118716</td>\n","      <td>-0.970241</td>\n","      <td>-0.125292</td>\n","      <td>-0.944507</td>\n","      <td>-0.977190</td>\n","      <td>0.241200</td>\n","      <td>-0.269667</td>\n","      <td>0.189351</td>\n","      <td>0.181290</td>\n","      <td>...</td>\n","      <td>-0.227695</td>\n","      <td>-0.219675</td>\n","      <td>-0.348739</td>\n","      <td>0.594702</td>\n","      <td>-0.777287</td>\n","      <td>-0.378595</td>\n","      <td>-0.372857</td>\n","      <td>0.435433</td>\n","      <td>0.070352</td>\n","      <td>0.999995</td>\n","      <td>-0.859133</td>\n","      <td>-0.928382</td>\n","      <td>-0.434548</td>\n","      <td>-0.349002</td>\n","      <td>0.312163</td>\n","      <td>-0.296398</td>\n","      <td>-1.0</td>\n","      <td>0.090986</td>\n","      <td>-0.733399</td>\n","      <td>0.795553</td>\n","      <td>-0.807325</td>\n","      <td>0.921434</td>\n","      <td>-0.501338</td>\n","      <td>-0.788751</td>\n","      <td>-0.087494</td>\n","      <td>0.801062</td>\n","      <td>0.885823</td>\n","      <td>-0.373333</td>\n","      <td>-0.343366</td>\n","      <td>0.600299</td>\n","      <td>-0.545601</td>\n","      <td>0.980657</td>\n","      <td>0.575146</td>\n","      <td>0.135790</td>\n","      <td>0.120160</td>\n","      <td>0.696775</td>\n","      <td>-0.911567</td>\n","      <td>-0.503772</td>\n","      <td>0.692356</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.410833</td>\n","      <td>-0.506333</td>\n","      <td>-0.995662</td>\n","      <td>0.530960</td>\n","      <td>0.960250</td>\n","      <td>-0.236363</td>\n","      <td>-0.282453</td>\n","      <td>0.447984</td>\n","      <td>-0.960383</td>\n","      <td>-0.999265</td>\n","      <td>-0.781264</td>\n","      <td>0.974797</td>\n","      <td>0.893978</td>\n","      <td>0.797164</td>\n","      <td>0.428669</td>\n","      <td>-0.476356</td>\n","      <td>0.003985</td>\n","      <td>-0.647214</td>\n","      <td>0.304032</td>\n","      <td>0.872063</td>\n","      <td>0.531742</td>\n","      <td>1.000000</td>\n","      <td>-0.455619</td>\n","      <td>0.363179</td>\n","      <td>0.364398</td>\n","      <td>0.995275</td>\n","      <td>-0.730364</td>\n","      <td>0.680403</td>\n","      <td>0.570509</td>\n","      <td>0.578997</td>\n","      <td>0.228405</td>\n","      <td>0.039234</td>\n","      <td>-0.953021</td>\n","      <td>-0.277550</td>\n","      <td>-0.998966</td>\n","      <td>-0.962857</td>\n","      <td>0.441451</td>\n","      <td>-0.007218</td>\n","      <td>-0.027191</td>\n","      <td>0.172031</td>\n","      <td>...</td>\n","      <td>-0.360532</td>\n","      <td>-0.351759</td>\n","      <td>-0.493682</td>\n","      <td>0.436126</td>\n","      <td>-0.871435</td>\n","      <td>-0.586574</td>\n","      <td>-0.393124</td>\n","      <td>0.491337</td>\n","      <td>0.285180</td>\n","      <td>1.000000</td>\n","      <td>-0.982884</td>\n","      <td>-0.977736</td>\n","      <td>-0.594445</td>\n","      <td>-0.442828</td>\n","      <td>0.509552</td>\n","      <td>-0.372019</td>\n","      <td>-1.0</td>\n","      <td>0.203671</td>\n","      <td>-0.767502</td>\n","      <td>0.953264</td>\n","      <td>-0.941762</td>\n","      <td>0.990971</td>\n","      <td>-0.633268</td>\n","      <td>-0.637323</td>\n","      <td>-0.443813</td>\n","      <td>0.915532</td>\n","      <td>0.961086</td>\n","      <td>-0.354065</td>\n","      <td>-0.199670</td>\n","      <td>0.555582</td>\n","      <td>-0.100036</td>\n","      <td>0.997626</td>\n","      <td>0.311818</td>\n","      <td>-0.217166</td>\n","      <td>-0.397853</td>\n","      <td>0.669593</td>\n","      <td>-0.970973</td>\n","      <td>-0.529365</td>\n","      <td>0.628633</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 769 columns</p>\n","</div>"],"text/plain":["          0         1         2  ...       766       767  sentiment\n","0 -0.392885 -0.382007 -0.938229  ... -0.435742  0.390948          0\n","1 -0.776412 -0.479143 -0.966163  ... -0.651949  0.812310          0\n","2 -0.532591 -0.387242 -0.952996  ... -0.570303  0.546067          0\n","3 -0.594817 -0.403342 -0.953941  ... -0.503772  0.692356          0\n","4 -0.410833 -0.506333 -0.995662  ... -0.529365  0.628633          0\n","\n","[5 rows x 769 columns]"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"46LGa84M8pOw","executionInfo":{"status":"ok","timestamp":1619068419632,"user_tz":300,"elapsed":12362,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["# Warning: this file will be large, about 150MB\n","feature_df.to_csv(\"/content/drive/MyDrive/AMA/12_NLP_using_BERT/IMDB_small_BERT.csv\", index=False)"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bgAk3J6zDf2y"},"source":["## Building and evaluating the prediction model\n","\n","The rest is similar to what we did with the business loan dataset earlier this semester. I'll use the simple logistic regression model."]},{"cell_type":"code","metadata":{"id":"WSd-GQC1VolF","executionInfo":{"status":"ok","timestamp":1619068439047,"user_tz":300,"elapsed":1005,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["from sklearn.model_selection import train_test_split"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"gRVdYop0VKjN","executionInfo":{"status":"ok","timestamp":1619068444341,"user_tz":300,"elapsed":509,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["X = feature_df.drop(columns=['sentiment'])\n","y = feature_df['sentiment']\n","\n","# reserve 30% dataset as testing\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n","                                                    random_state=1,\n","                                                    stratify=y)"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"IczZQOIUCqWD","executionInfo":{"status":"ok","timestamp":1619068457220,"user_tz":300,"elapsed":384,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["model2 = models.Sequential()\n","model2.add(layers.Dense(128, activation='relu', input_dim=768))\n","# model2.add(layers.Dropout(0.5))\n","model2.add(layers.Dense(1, activation='sigmoid'))"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"h9KN2l8HWXJa","executionInfo":{"status":"ok","timestamp":1619068460816,"user_tz":300,"elapsed":490,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}}},"source":["model2.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['acc'])"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"NlwtEMbuXg3k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619068462543,"user_tz":300,"elapsed":330,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"7ad1decb-65a7-4d48-ecf4-6d9a5d32c0f1"},"source":["model2.summary()"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 128)               98432     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 129       \n","=================================================================\n","Total params: 98,561\n","Trainable params: 98,561\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MJZGmll0Wu0b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619068488023,"user_tz":300,"elapsed":16605,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"2e593c17-bcea-4788-9e97-3c31f8a64749"},"source":["model2.fit(X_train, y_train, epochs=30)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.6770 - acc: 0.6097\n","Epoch 2/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.5195 - acc: 0.7486\n","Epoch 3/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4815 - acc: 0.7800\n","Epoch 4/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4386 - acc: 0.7998\n","Epoch 5/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4296 - acc: 0.8068\n","Epoch 6/30\n","219/219 [==============================] - 0s 2ms/step - loss: 0.4342 - acc: 0.7918\n","Epoch 7/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4198 - acc: 0.8060\n","Epoch 8/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4144 - acc: 0.8112\n","Epoch 9/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4262 - acc: 0.8081\n","Epoch 10/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4071 - acc: 0.8129\n","Epoch 11/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3942 - acc: 0.8219\n","Epoch 12/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3880 - acc: 0.8240\n","Epoch 13/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3861 - acc: 0.8265\n","Epoch 14/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3763 - acc: 0.8362\n","Epoch 15/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3739 - acc: 0.8303\n","Epoch 16/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3644 - acc: 0.8326\n","Epoch 17/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3896 - acc: 0.8255\n","Epoch 18/30\n","219/219 [==============================] - 0s 2ms/step - loss: 0.3745 - acc: 0.8285\n","Epoch 19/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3718 - acc: 0.8324\n","Epoch 20/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3626 - acc: 0.8415\n","Epoch 21/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3786 - acc: 0.8278\n","Epoch 22/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3804 - acc: 0.8273\n","Epoch 23/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3679 - acc: 0.8375\n","Epoch 24/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3884 - acc: 0.8271\n","Epoch 25/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3753 - acc: 0.8323\n","Epoch 26/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3527 - acc: 0.8433\n","Epoch 27/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3620 - acc: 0.8376\n","Epoch 28/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3596 - acc: 0.8433\n","Epoch 29/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.4000 - acc: 0.8211\n","Epoch 30/30\n","219/219 [==============================] - 1s 2ms/step - loss: 0.3572 - acc: 0.8432\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd86229d310>"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"_RRh4XkYXuw7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619068507907,"user_tz":300,"elapsed":698,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"d7c95ebd-0829-4133-ecc9-8cd57f3475d1"},"source":["test_loss, test_acc = model2.evaluate(X_test,  y_test, verbose=2)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["94/94 - 0s - loss: 0.3827 - acc: 0.8313\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W-sBWYvAXzer","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619068522679,"user_tz":300,"elapsed":525,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"8e7a0cbf-083a-4bc1-ce25-e97db90643dc"},"source":["# prediction\n","model2.predict(X_test.iloc[[0]])"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.1053965]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"ZdCN6PUCYnGm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619068527153,"user_tz":300,"elapsed":360,"user":{"displayName":"Xianjun Geng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64","userId":"03603659341670711497"}},"outputId":"091227b8-08fc-4714-edf6-b8ba16a36996"},"source":["print(y_test[0])"],"execution_count":46,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]}]}