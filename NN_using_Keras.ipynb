{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NN using Keras.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"aKhoCKCr_nuo"},"source":["# Neural Network in Keras -- a Case Study of the Fashion MNIST Dataset\n","\n","This code is based the (more extensive) Keras classification tutorial at (https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb)."]},{"cell_type":"code","metadata":{"id":"CDf7WYohrsZF"},"source":["import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yR0EdgrLCaWR"},"source":["## Import the Fashion MNIST dataset"]},{"cell_type":"code","metadata":{"id":"7MqDQO0KCaWS"},"source":["fashion_mnist = keras.datasets.fashion_mnist\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t9FDsUlxCaWW"},"source":["The [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset contains 70,000 grayscale images -- 60,000 for training and 10,000 for testing. Each image is of size 28 pixels by 28 pixels, and shows a piece of clothes -- see the example below."]},{"cell_type":"code","metadata":{"id":"3qx5wDuTqPlV"},"source":["train_images.shape, test_images.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQA6_5SqrJe2"},"source":["plt.figure()\n","plt.imshow(train_images[0], cmap=plt.cm.binary)\n","plt.colorbar()\n","plt.grid(False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ltHHXRhqOCJ"},"source":["Each image is represented by a 28x28 NumPy array, with pixel values ranging from 0 to 255. For example, the image above is presented as:"]},{"cell_type":"code","metadata":{"id":"2r_sMFZ6q7y3","collapsed":true},"source":["print(train_images[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I6aAIA9d3zzH"},"source":["These clothes belong to 10 categories/classes (so this is a 10-class prediction problem rather than a binary prediction problem). These 10 classes are:"]},{"cell_type":"code","metadata":{"id":"IjnLH5S2CaWx"},"source":["class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFBB1wLK4hyL"},"source":["print(f\"The image above has a target/label value of {train_labels[0]}.\")\r\n","print(f\"Therefore, it is an image of {class_names[train_labels[0]]}.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ee638AlnCaWz"},"source":["Let's plot a few more for fun:"]},{"cell_type":"code","metadata":{"id":"oZTImqg_CaW1"},"source":["plt.figure(figsize=(10,10))\n","for i in range(25):\n","    plt.subplot(5,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(train_images[i], cmap=plt.cm.binary)\n","    plt.xlabel(class_names[train_labels[i]])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ES6uQoLKCaWr"},"source":["## Normalize the data"]},{"cell_type":"markdown","metadata":{"id":"Wz7l27Lz9S1P"},"source":["Modern NN prefers (and often requires) input data being normalized/standardized -- a topic related to how optimizers work and how regularization works. For bounded data such as this one where values range between 0 and 255, we need to normalize it so that it is within the range of 0 to 1. For this dataset, it means dividing the values by 255. It's important that the *training set* and the *testing set* be preprocessed in the same way:"]},{"cell_type":"code","metadata":{"id":"bW5WzIPlCaWv"},"source":["train_images = train_images / 255.0\n","test_images = test_images / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"59veuiEZCaW4"},"source":["## Build the model\n","\n","Two steps: 1. Set up the layers. 2. Compile the model."]},{"cell_type":"markdown","metadata":{"id":"Gxg1XGm0eOBy"},"source":["### Set up the layers\r\n","\r\n","Our goal today is to have a basic feel of how to build a NN model using Keras. We will gradually learn more of the Keras package and related programming details."]},{"cell_type":"code","metadata":{"id":"9ODch-OFCaW4"},"source":["model = keras.Sequential([\n","    keras.layers.Flatten(input_shape=(28, 28)),\n","    keras.layers.Dense(128, activation='relu'),\n","    keras.layers.Dense(10, activation='softmax')\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gut8A_7rCaW6"},"source":["The first layer in this network, `tf.keras.layers.Flatten`, transforms the format of the images from a two-dimensional array (of shape (28, 28)) to a one-dimensional array (of shape (784)). Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn; it only reformats the data.\n","\n","After the pixels are flattened, the network consists of a sequence of two `tf.keras.layers.Dense` layers. These are densely connected, or fully connected, neural layers. The first `Dense` layer has 128 nodes (or neurons). The second `Dense` layer has 10 nodes. Notice that these two dense layers use different activation functions (why?)."]},{"cell_type":"code","metadata":{"id":"A_2kqvGH5KkL"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BLWq2JMQx6DD"},"source":["### Compile the model\n","\n","The model's *compile* step allows us to specify the *loss function*, the *optimizer*, and the *metrics*:"]},{"cell_type":"code","metadata":{"id":"Lhan11blCaW7"},"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qKF6uW-BCaW-"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"xvwvpA64CaW_"},"source":["model.fit(train_images, train_labels, epochs=10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W3ZVOhugCaXA"},"source":["As the model trains, the loss and accuracy metrics (of every epoch) are displayed. This model reaches an accuracy of about 93.0% on the training dataset."]},{"cell_type":"markdown","metadata":{"id":"wCpr6DGyE28h"},"source":["## Evaluate accuracy\n","\n","Next, compare how the model performs on the test dataset:"]},{"cell_type":"code","metadata":{"id":"VflXLEeECaXC"},"source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","\n","print('\\nTest accuracy:', test_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yWfgsmVXCaXG"},"source":["The accuracy on the test dataset, 88.86%, is only slightly less than the accuracy on the training dataset. Therefore, overfitting is not a significant concern in this model."]},{"cell_type":"markdown","metadata":{"id":"v-PyD1SYE28q"},"source":["## Make predictions"]},{"cell_type":"code","metadata":{"id":"Gl91RPhdCaXI"},"source":["predictions = model.predict(test_images)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x9Kk1voUCaXJ"},"source":["Here, the model has predicted the label for each image in the testing set. Let's take a look at the first prediction:"]},{"cell_type":"code","metadata":{"id":"3DmJEUinCaXK"},"source":["predictions[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KG4mVsgk9GE-"},"source":["predicted_value = class_names[predictions[0].argmax()]\r\n","ground_truth = class_names[test_labels[0]]\r\n","print(f\"Our trained NN model predicts that the first test image is a(an) {predicted_value}.\")\r\n","print(f\"The ground truth is a(an) {ground_truth}.\")\r\n","\r\n","verdict = 'correct' if predicted_value==ground_truth else 'incorrect'\r\n","print(f\"Therefore, this prediction is {verdict}.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kXKwv8cn-l8A"},"source":["(Not required for our course) Below are codes for more visually-fancy prediction for the first 15 records:"]},{"cell_type":"code","metadata":{"id":"DvYmmrpIy6Y1"},"source":["def plot_image(i, predictions_array, true_label, img):\n","  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","\n","  plt.imshow(img, cmap=plt.cm.binary)\n","\n","  predicted_label = np.argmax(predictions_array)\n","  if predicted_label == true_label:\n","    color = 'blue'\n","  else:\n","    color = 'red'\n","\n","  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n","                                100*np.max(predictions_array),\n","                                class_names[true_label]),\n","                                color=color)\n","\n","def plot_value_array(i, predictions_array, true_label):\n","  predictions_array, true_label = predictions_array, true_label[i]\n","  plt.grid(False)\n","  plt.xticks(range(10))\n","  plt.yticks([])\n","  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n","  plt.ylim([0, 1])\n","  predicted_label = np.argmax(predictions_array)\n","\n","  thisplot[predicted_label].set_color('red')\n","  thisplot[true_label].set_color('blue')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hQlnbqaw2Qu_"},"source":["# Plot the first X test images, their predicted labels, and the true labels.\n","# Color correct predictions in blue and incorrect predictions in red.\n","num_rows = 5\n","num_cols = 3\n","num_images = num_rows*num_cols\n","plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n","for i in range(num_images):\n","  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n","  plot_image(i, predictions[i], test_labels, test_images)\n","  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n","  plot_value_array(i, predictions[i], test_labels)\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]}]}